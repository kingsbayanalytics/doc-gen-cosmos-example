# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

This is a Prompt Flow project that enables natural language querying of workout data stored in Azure Cosmos DB. Users can ask questions in plain English, which are converted to SQL queries and executed against their fitness tracking data.

## Architecture

The system follows this flow:
1. User asks a natural language question (e.g., "How many strength exercises did I do last week?")
2. Azure OpenAI GPT-4o converts the question to a Cosmos DB SQL query
3. The SQL query is executed against Cosmos DB
4. Results are returned to the user in JSON format

## Key Components

- **csv_to_jsonl.py**: Converts CSV workout data to JSONL format for Cosmos DB ingestion
- **load_csv_to_cosmos.py**: Uploads JSONL data to Azure Cosmos DB with proper error handling
- **query_interpreter.py**: Uses Azure OpenAI to convert natural language to SQL
- **cosmos_query_runner.py**: Executes SQL queries against Cosmos DB and formats results
- **flow.dag.yaml**: Prompt Flow DAG that orchestrates the query pipeline

## Development Commands

```bash
# Convert CSV to JSONL
python workout-data-promptflow/csv_to_jsonl.py "Workout Entries SP.csv" workout_entries_cosmos.jsonl

# Upload data to Cosmos DB
cd workout-data-promptflow
python load_csv_to_cosmos.py

# Run Prompt Flow locally
pf run --flow . --inputs query="How many sets did I do last week?"

# Test individual components
python query_interpreter.py
python cosmos_query_runner.py

# Test framework robustness
python test_framework_robustness.py
```

## Data Schema

Workout data contains these fields:
- `id`: Unique identifier (e.g., "entry_1")
- `ExDate`: Exercise date
- `Exercise`: Exercise name
- `Set`: Set number
- `Reps`: Number of repetitions
- `Weight`: Weight used
- `ExType`: Exercise type (e.g., "Strength", "Cardio")

## Environment Variables

Required in `.env` file:
- `COSMOS_URI`: Azure Cosmos DB endpoint
- `COSMOS_KEY`: Primary key for authentication
- `COSMOS_DB`: Database name (sql-test)
- `COSMOS_CONTAINER`: Container name (sql-test)
- `AZURE_OPENAI_API_KEY`: Azure OpenAI API key
- `AZURE_OPENAI_ENDPOINT`: Azure OpenAI endpoint
- `AZURE_OPENAI_CHAT_DEPLOYMENT`: GPT-4o deployment name
- `AZURE_OPENAI_API_VERSION`: API version (2025-01-01-preview)

## Testing

When testing queries, ensure:
1. Environment variables are properly set
2. Cosmos DB container has data loaded
3. Azure OpenAI connection is active
4. Test with various natural language queries to verify SQL generation

## Future Enhancements

- Integration with Azure AI Search for vector-based semantic search
- Support for more complex workout analytics
- Caching layer for frequently asked questions
- Export functionality for query results

## Document Generation Integration

This project integrates with Microsoft's Document Generation Solution Accelerator to enable:
- RAG chat with fitness data via PromptFlow endpoint
- Auto-populated document templates with LLM-generated fitness insights
- Export capabilities for workout summaries, progress reports, and training plans

### Integration Architecture
The enhanced PromptFlow system serves as the backend data engine for document generation:
- PromptFlow endpoint provides intelligent workout analysis
- Document generation frontend consumes PromptFlow responses
- Templates auto-populate with personalized fitness insights
- Users can export as Word documents

### Key Files for Document Generation
- `DOCUMENT_GENERATION_PLAN.md` - Complete integration plan
- `DOCGEN_ENV_TEMPLATE.env` - Environment variables template
- PromptFlow must be deployed as Azure ML endpoint for integration

### Document Generation Workflow
1. **Template Generation**: User requests document template structure (‚úÖ Working)
2. **Section Generation**: System populates each template section with specific content (‚úÖ Working)
3. **Draft Assembly**: Combines sections into complete document (‚úÖ Working)  
4. **Export**: Generates formatted Word document (‚úÖ Working)

### Section Generation Rules
When implementing section generation endpoints:
- Use PromptFlow for data analysis and content generation
- Maintain dual-LLM approach (PromptFlow + Azure OpenAI)
- Each section should receive specific context and requirements
- Generate content that matches the section's purpose and tone
- Preserve workout data insights while formatting for document consumption

### Current Status
- **Template Generation**: ‚úÖ Fully operational with dual-LLM approach
- **Section Generation**: ‚úÖ Complete PromptFlow integration with real workout data
- **Frontend State Management**: ‚úÖ Robust navigation and rendering
- **Document Assembly**: ‚úÖ Automatic section combination and formatting
- **Word Export**: ‚úÖ Professional document generation with fitness insights

### ‚úÖ INTEGRATION COMPLETED Successfully!

The PromptFlow Document Generation integration is now **fully operational**:

**Complete Workflow**: Template Generation ‚Üí Section Population ‚Üí Draft Assembly ‚Üí Word Export

**Key Features**:
- Dual-LLM architecture (PromptFlow + Azure OpenAI)
- Real workout data integration (Cosmos DB + Azure AI Search)
- Professional Word document generation
- Robust frontend state management
- Error-free navigation and rendering

**Usage**: Navigate to http://localhost:5174/#/generate to test the complete workflow.

## Document Generation Integration - Design Decisions & Status

### ‚úÖ Completed Integration Steps

#### 1. **PromptFlow Backend Integration**
- **Status**: ‚úÖ WORKING
- **Decision**: Use existing PromptFlow as data source for document generation
- **Implementation**: Document generation app consumes PromptFlow endpoint via REST API
- **Key Files**: `src/backend/promptflow_handler.py`, `src/app.py`

#### 2. **Browse/Chat Functionality** 
- **Status**: ‚úÖ WORKING
- **Decision**: Maintain original chat interface with PromptFlow integration
- **Implementation**: Chat page successfully queries workout data and displays insights
- **Example**: "How many pushups have I done?" ‚Üí "You've performed 3,226 pushups!"

#### 3. **Data Quality Fixes**
- **Status**: ‚úÖ WORKING
- **Decision**: Implement schema-aware SQL generation for robust data access
- **Implementation**: 
  - `schema_discovery.py`: Auto-discovers database field names and categorical values
  - `query_interpreter.py`: Maps natural language to exact database values ("pushups" ‚Üí "Pushup")
  - `StringToNumber()` conversion for string-stored numeric fields
- **Impact**: Eliminated "no data found" errors, now returns real workout statistics

#### 4. **Chat History Infrastructure**
- **Status**: ‚úÖ WORKING
- **Decision**: Use separate CosmosDB container for conversation history
- **Implementation**: 
  - CosmosDB setup: `sql-test` database, `conversations` container
  - Environment configuration: `AZURE_COSMOSDB_*` variables in `src/.env`
  - Backend gracefully handles disabled chat history for PromptFlow-only mode

### üîß Current Issue: Template Generation

#### **Problem**: "No content in messages object" error when generating templates

#### **Root Cause Analysis**:
1. **Original Design**: Template generation expects structured JSON response with document sections
2. **Current Behavior**: PromptFlow returns workout data analysis (not template structure)
3. **Format Mismatch**: Frontend expects `{"template": [{"section_title": "...", "section_description": "..."}]}`
4. **Current Output**: Enhanced fitness analysis text

### üìã Recommended Solution Path (Staying True to Original Design)

#### **Option A: Minimal Backend Modification (RECOMMENDED)**
- **Principle**: Keep PromptFlow unchanged, add template formatting logic in document generation backend
- **Implementation**: 
  1. Detect template requests via `ChatType.TEMPLATE` 
  2. Call PromptFlow for workout data analysis
  3. Transform PromptFlow response into template JSON structure
  4. Use workout insights to populate section descriptions
- **Pros**: No PromptFlow changes, follows original architecture
- **Cons**: Requires backend logic to convert analysis to template format

#### **Option B: Dual System Message Approach**
- **Principle**: Use different system messages for template vs. browse requests
- **Implementation**: Modify template requests to use `AZURE_OPENAI_TEMPLATE_SYSTEM_MESSAGE` instead of PromptFlow
- **Pros**: Leverages original template generation design
- **Cons**: Templates wouldn't include actual workout data insights

#### **Option C: PromptFlow Extension** 
- **Principle**: Add template generation capability to PromptFlow
- **Implementation**: Add conditional logic to return template JSON when template keywords detected
- **Pros**: Single source of truth, data-driven templates
- **Cons**: Modifies PromptFlow significantly, deviates from original design

### üéØ Next Steps (Incremental Testing)

#### **Step 1: Understand Current Template Flow**
- [ ] Test original template generation with Azure AI Search disabled
- [ ] Verify `AZURE_OPENAI_TEMPLATE_SYSTEM_MESSAGE` behavior in isolation
- [ ] Document exact request/response format expected by frontend

#### **Step 2: Implement Option A (Backend Transform)**
- [ ] Add template detection logic in `conversation_internal()`
- [ ] Create function to transform PromptFlow analysis into template JSON
- [ ] Test with simple template request: "Create a monthly pushup report template"

#### **Step 3: Validate Template Structure**
- [ ] Ensure JSON format matches `DraftedDocument` model
- [ ] Test frontend parsing of generated template
- [ ] Verify template history saves correctly

#### **Step 4: Content Generation Integration**
- [ ] Test section content generation using PromptFlow data
- [ ] Ensure individual sections can be populated with workout insights
- [ ] Verify Word document export functionality

### üîÑ Design Principles Maintained
1. **Minimal Code Changes**: Reuse existing PromptFlow for data access
2. **Original Architecture**: Keep template/browse separation intact  
3. **Data-Driven**: Templates populated with real workout analytics
4. **Incremental Progress**: Each step independently testable
5. **Fallback Capability**: Template generation can fall back to Azure OpenAI if needed

## üìã Repository Structure (Updated)

After repository optimization, the structure is now:

```
promptflow-sql/
‚îú‚îÄ‚îÄ docs/                                          # üìÅ All documentation
‚îÇ   ‚îú‚îÄ‚îÄ DOCUMENT_GENERATION_PLAN.md
‚îÇ   ‚îú‚îÄ‚îÄ DOCUMENT_GENERATION_SECTION_ANALYSIS.md
‚îÇ   ‚îú‚îÄ‚îÄ PROMPTFLOW_DOCUMENT_GENERATION_INTEGRATION.md
‚îÇ   ‚îú‚îÄ‚îÄ PROMPTFLOW_INTEGRATION_FINAL_SUMMARY.md
‚îÇ   ‚îú‚îÄ‚îÄ PROMPTFLOW_INTEGRATION_SUCCESS_SUMMARY.md
‚îÇ   ‚îî‚îÄ‚îÄ REPOSITORY_OPTIMIZATION.md
‚îú‚îÄ‚îÄ workout-data-promptflow/                       # üîÑ Renamed from csv-promptflow-test
‚îÇ   ‚îú‚îÄ‚îÄ .env.example                              # Environment template
‚îÇ   ‚îú‚îÄ‚îÄ flow.dag.yaml                             # PromptFlow definition
‚îÇ   ‚îú‚îÄ‚îÄ query_interpreter.py                      # SQL query generation
‚îÇ   ‚îú‚îÄ‚îÄ cosmos_query_runner.py                    # Cosmos DB integration
‚îÇ   ‚îú‚îÄ‚îÄ search_query_runner.py                    # Azure AI Search
‚îÇ   ‚îú‚îÄ‚îÄ llm_enhancer.py                          # Result enhancement
‚îÇ   ‚îú‚îÄ‚îÄ test_framework_robustness.py             # Comprehensive tests
‚îÇ   ‚îî‚îÄ‚îÄ ... (other PromptFlow files)
‚îú‚îÄ‚îÄ document-generation-solution-accelerator/     # üìÑ Document generation system
‚îÇ   ‚îú‚îÄ‚îÄ src/backend/                              # Backend integration
‚îÇ   ‚îú‚îÄ‚îÄ src/frontend/                             # React frontend
‚îÇ   ‚îú‚îÄ‚îÄ src/.env.example                          # Environment template
‚îÇ   ‚îî‚îÄ‚îÄ ... (Microsoft solution accelerator)
‚îú‚îÄ‚îÄ .gitignore                                     # üîí Comprehensive exclusions
‚îú‚îÄ‚îÄ README.md                                      # üìñ Complete implementation guide
‚îî‚îÄ‚îÄ CLAUDE.md                                      # üìã Project instructions (this file)
```

## üìã Critical Development Rule: PromptFlow Integration Documentation

**MANDATORY**: When working on PromptFlow Document Generation integration, ALWAYS:

1. **Reference**: Check `docs/PROMPTFLOW_DOCUMENT_GENERATION_INTEGRATION.md` for current status
2. **Update**: Modify the integration document after any changes to:
   - Backend integration code (`src/app.py`)
   - PromptFlow configuration 
   - Frontend parsing fixes
   - Environment setup
   - Testing protocols
3. **Track Progress**: Update status sections (‚úÖ WORKING, üîß IN PROGRESS, ‚ùå BROKEN)
4. **Document Issues**: Add any new problems to the troubleshooting section
5. **Preserve Knowledge**: Ensure future developers can understand the integration without context

**Key Files to Maintain**:
- `docs/PROMPTFLOW_DOCUMENT_GENERATION_INTEGRATION.md` - Primary integration documentation
- `README.md` - Complete implementation guide and developer reference
- `CLAUDE.md` - This file (high-level project guidance)
- `docs/DOCUMENT_GENERATION_PLAN.md` - Original planning document

**Before Making Changes**: Read the integration document to understand current state
**After Making Changes**: Update the integration document with new status and learnings

This rule prevents regression and ensures the complex PromptFlow + Document Generation integration remains maintainable for future developers modifying the Microsoft Document Generation Solution Accelerator.